category: Data Enrichment & Threat Intelligence
commonfields:
  id: RecordedFutureASI_copy
  version: -1
configuration:
- display: Fetch incidents
  name: isFetch
  required: false
  type: 8
- display: API Key
  hidden: true
  name: apikey
  required: false
  type: 4
- display: API Key
  displaypassword: API Key
  hiddenusername: true
  name: credentials
  required: false
  type: 9
- additionalinfo: The Project ID to fetch issues from
  display: Project ID
  name: project_id
  required: true
  type: 4
- defaultvalue: Recorded Future ASI Alert
  display: Incident type
  name: incidentType
  required: false
  type: 13
- defaultvalue: Informational
  display: Minimum severity of alerts to fetch
  name: min_severity
  options:
  - Informational
  - Moderate
  - Critical
  required: false
  type: 15
- defaultvalue: By Issue
  display: How to group new issues
  name: issue_grouping
  options:
  - By Host
  - By Issue
  required: false
  type: 15
- defaultvalue: "false"
  display: Expand grouped By Host rules into separate Incidents (applicable if grouping
    By Host)
  name: expand_issues
  required: false
  type: 8
- additionalinfo: Maximum number of incidents per fetch
  defaultvalue: "200"
  display: Fetch limit
  name: max_fetch
  required: false
  type: 0
- defaultvalue: 24 hours
  display: First fetch time (<number> <time unit>, e.g., 12 hours, 7 days, 3 months,
    1 year)
  name: first_fetch
  required: false
  type: 0
- defaultvalue: "1"
  display: Incidents Fetch Interval
  name: incidentFetchInterval
  required: false
  type: 19
- defaultvalue: "false"
  display: Trust any certificate (not secure)
  name: insecure
  required: false
  type: 8
- defaultvalue: "false"
  display: Use system proxy settings
  name: proxy
  required: false
  type: 8
contentitemexportablefields:
  contentitemfields:
    definitionid: ""
    fromServerVersion: ""
    itemVersion: ""
    packID: ""
    packName: ""
    prevname: ""
    propagationLabels:
    - all
    toServerVersion: ""
description: Attack Surface Intelligence Risk Rules help security teams take risk
  and vulnerability prioritization to the next level by helping organizations identify
  the biggest weaknesses within their attack surface in mere seconds.
detaileddescription: |-
  ### Partner Contributed Integration
  #### Integration Author: Recorded Future
  Support and maintenance for this integration are provided by the author. Please use the following contact details:
  - **Email**: [support@recordedfuture.com](mailto:support@recordedfuture.com)
  ***
  ### What does this pack do?
  #### This pack enables security teams to:

  - Access a unified risk management from the most popular SOAR platform.
  - Visualize to the most critical risks within your organization
  - Identify security incidents filtered by severity (critical, medium and low)
  - See the full context of the incident, including CVE id, name, description, and affected hostnames.

  ### Configure RecordedFutureASI on Cortex XSOAR
  #### Get your Project ID
  - Log in to SecurityTrails SurfaceBrowser
  - Go to the Projects page by clicking the `Projects` link in the top right
  - Click on the Project that you want to use in XSOAR
  - Copy the ID from the URL (looks like `c1234567-c123-4123-9123-0123456789ab`)

  #### Get your API Key
  - Log in to SecurityTrails SurfaceBrowser
  - Click the username in the top right corner
  - Click on Account
  - Go to API > API Keys
  - Create a new API key with a note that it is being used for the XSOAR Integration

  #### Setting up the Integration
  1. Navigate to **Settings** > **Integrations** > **Servers & Services**.
  2. Search for RecordedFutureASI.
  3. Click **Add instance** to create and configure a new integration instance.

  | **Parameter**                                                                                      | **Required**  |
  |---------------|----------------------------------------------------------------------------------------------------|
  | API Key                                                                                            | True          |
  | Project ID                                                                                         | True          |
  | Min Severity                                                                                       | False         |
  | Issue Grouping                                                                                     | False         |
  | Expand Issues                                                                                      | False         |
  | Fetch incidents                                                                                    | False         |
  | Incidents Fetch Interval                                                                           | False         |
  | Incident type                                                                                      | False         |
  | First fetch timestamp (&lt;number&gt; &lt;time unit&gt;, e.g., 12 hours, 7 days, 3 months, 1 year) | False         |
  | Max Fetch                                                                                          | False         |

  5. Click **Test** to validate the token and connection.

  ---
  [View Integration Documentation](https://xsoar.pan.dev/docs/reference/integrations/recorded-future-asi)
display: RecordedFutureASI_copy
image: data:image/png;base64,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
name: RecordedFutureASI_copy
script:
  commands:
  - arguments:
    - description: timestamp to get incidents after.
      name: issues_start
    - description: true/false whether to group incidents by changed host.
      name: group_by_host
    - description: true/false to make an incident per host & per new issue.
      name: expand_issues
    description: Gets the issues for a project from a particular snapshot (defaults
      to recent).
    name: asi-project-issues-fetch
  dockerimage: demisto/python3:3.10.14.91134
  isfetch: true
  runonce: false
  script: |
    register_module_line('RecordedFutureASI', 'start', __line__())
    ### pack version: 2.0.15




    import time
    import urllib3
    import traceback
    from abc import ABC
    from datetime import datetime
    from collections import defaultdict
    from typing import Any, Dict, Tuple, List, Union

    # Disable insecure warnings
    urllib3.disable_warnings()

    ''' CONSTANTS '''

    DATE_FORMAT = '%Y-%m-%d %H:%M:%S'
    DEFAULT_HOST_LIMIT = 200
    DEFAULT_MIN_SEVERITY = 'Moderate'
    CRITICALITY_TITLES = {
        'informational': 'Informational',
        'moderate': 'Moderate',
        'high': 'Critical'
    }
    SEVERITY_MAPPINGS = {
        'informational': IncidentSeverity.LOW,
        'moderate': IncidentSeverity.MEDIUM,
        'high': IncidentSeverity.CRITICAL
    }
    MIN_SEVERITY_MAPPING = {
        'Informational': 'high,moderate,informational',
        'Moderate': 'high,moderate',
        'Critical': 'high'
    }

    ''' CLIENT CLASS '''


    class Client(BaseClient):
        def __init__(self, *args,
                     project_id: str = None,
                     min_severity: str = DEFAULT_MIN_SEVERITY,
                     host_incident_limit: int = DEFAULT_HOST_LIMIT,
                     **kwargs):
            """
            Client subclass to handle API calls to the ASI API

            :param project_id: the project_id to scope the API calls to
            :param min_severity: the minimum rule severity to check for changes
            :param host_incident_limit: the max number of host incidents to return
            """
            super().__init__(*args, **kwargs)
            self.project_id = project_id
            self.min_severity = min_severity
            self.host_incident_limit = host_incident_limit

        def get_project_issues(self, snapshot: str) -> Dict:
            """
            Gets all the issues triggered for a particular snapshot

            NOTE :: This endpoint does not support filtering and will need to do it in function

            :param snapshot: date string formatted in DATE_FORMAT
            :return: Dict with a data key that is an array of issues
            """
            return self._http_request(
                method='GET',
                url_suffix=f'/rules/{self.project_id}/{snapshot}/issues'
            )

        def get_recent_issues(self, last_run: Union[str, int]) -> Dict:
            """
            Lookup the added issues after a certain date

            :param last_run: can be a timestamp or a snapshot in DATE_FORMAT
            :return: Dict with a data key that is an array of diffs between snapshots
            """
            return self._http_request(
                method='GET',
                url_suffix=f'/rules/history/{self.project_id}/activity?'
                           f'rule_action=added&'
                           f'start={last_run}&'
                           f'classification={MIN_SEVERITY_MAPPING[self.min_severity]}'
            )

        def get_recent_issues_by_host(self, last_run: Union[str, int]) -> Dict:
            """
            Lookup the hosts that have added issues after a certain date by host

            :param last_run: can be a timestamp or a snapshot in DATE_FORMAT
            :return: Dict with a data key that is an array of diffs between snapshots
            """
            return self._http_request(
                method='GET',
                url_suffix=f'/rules/history/{self.project_id}/activity/by_host/compare?'
                           f'rule_action=added&'
                           f'last_checked={last_run}&'
                           f'classification={MIN_SEVERITY_MAPPING[self.min_severity]}&'
                           f'limit={self.host_incident_limit}'
            )


    ''' HELPER FUNCTIONS '''


    class IncidentBuilder:
        def __init__(self, min_severity: str, snapshot: Optional[str], last_checked: int = 0):
            """
            Class to standardize each API response and build the rawJSON for the Incident type

            :param min_severity: option selected by the user when setting up the Pack
            :param snapshot: snapshot that the risks came from
            :param last_checked: the timestamp since incidents were last checked for
            """
            self.min_severity = min_severity
            self.snapshot = snapshot
            self.last_checked = last_checked
            self.incident_created_time = 0 if not snapshot else datetime.strptime(snapshot, DATE_FORMAT).timestamp()
            self.incident_created_time_ms = self.incident_created_time * 1000

        def parse_rule(self, rule: Dict) -> Optional[Dict]:
            """
            Takes a rule from the ASI API and formats it into a better format for XSOAR

            :return: optionally a transformed Dict (None if rule gets filtered out)
            """
            raise NotImplementedError()

        def parse_rules(self, rules: List[Dict]) -> List[Dict]:
            """
            Given an array of rules, parse out relevant info and filter out ones to skip

            :param rules: list of rules from ASI API
            :return: list of transformed Dict to get built as Incidents
            """
            transformed = []

            # NOTE :: to prevent duplicates, we are only adding incidents with creation_time > last fetched incident
            if self.incident_created_time <= self.last_checked:
                return []

            for rule in rules:
                parsed_rule = self.parse_rule(rule)

                if parsed_rule is None:
                    continue

                # NOTE :: Some endpoints don't support filtering and will need to do it in function
                if parsed_rule['classification'] not in MIN_SEVERITY_MAPPING[self.min_severity]:
                    continue

                transformed.append(parsed_rule)
            return transformed

        def build_incident(self, parsed_rule: Dict) -> Dict:
            """
            Takes a standardized rule and builds an incident from it

            :param parsed_rule: standardized rule from ASI API
            :return: XSOAR Incident format
            """
            raise NotImplementedError()

        def build_incidents(self, parsed_rules: List[Dict]) -> List[Dict]:
            """
            Takes in parsed_rules and formats them as XSOAR Incident

            :param parsed_rules: parsed rules
            :return: list of Incident
            """
            return [self.build_incident(issue) for issue in parsed_rules]

        @staticmethod
        def _format_references(refs: List[str]) -> str:
            """
            Formats references as bulleted Long Text

            :param refs: list of reference links
            :return: bulleted list
            """
            return '\n\n'.join([f'◦ {r}' for r in refs])

        @staticmethod
        def _use_severity_titles(rules: List[Dict]) -> List[Dict]:
            """
            Swap out classifications to use CRITICALITY_TITLES instead

            :param rules: list of parsed rules
            :return: mutated rules
            """
            for r in rules:
                r['classification'] = CRITICALITY_TITLES[r['classification']]
            return rules


    class ByHostIncidentBuilder(IncidentBuilder, ABC):
        def __init__(self, host: str, risk_score: int, previous_score: int, previous_snapshot: Optional[str],
                     min_severity: str, snapshot: Optional[str], last_checked: int = 0):
            """
            Incident type where issues are grouped by hosts

            :param host: the host that changed (ip or domain)
            :param risk_score: the current score of the host
            :param previous_score: the previous score
            :param previous_snapshot: the last scanned snapshot
            :param min_severity: the min_severity configured by the user
            :param snapshot: the current snapshot
            :param last_checked: the last time the api was polled for changes
            """
            super().__init__(min_severity, snapshot, last_checked=last_checked)
            self.host = host
            self.risk_score = risk_score
            self.previous_snapshot = previous_snapshot
            self.previous_score = previous_score or 0

        def parse_rule(self, rule: Dict) -> Optional[Dict]:
            return {
                'name': rule['name'],
                'details': rule['description'],
                'classification': rule['classification'],
                'references': self._format_references(rule.get('rule_metadata', {}).get('references', [])),
                'metadata': rule.get('rule_metadata', {}).get('target', rule.get('rule_metadata', {}).get('additional'))
            }


    class ByIssueIncident(IncidentBuilder):
        def parse_rule(self, rule: Dict) -> Optional[Dict]:
            hosts = self._build_examples(rule['example_entities'].get('domains', [])) + \
                self._build_examples(rule['example_entities'].get('ips', []))
            return {
                'name': rule['name'],
                'details': rule['description'],
                'classification': rule['classification'],
                'entity_counts': rule.get('rule_metadata', {}).get('entity_counts', {}),
                'references': self._format_references(rule.get('rule_metadata', {}).get('references', [])),
                'hosts': hosts
            }

        def build_incident(self, parsed_rule: Dict) -> Dict:
            count_copy = '\n\nThis rule triggered for '
            entity_counts = parsed_rule.pop('entity_counts')
            examples = parsed_rule.pop('hosts', [])
            domain_count = entity_counts.get('domains')
            ip_count = entity_counts.get('ips')
            if domain_count and ip_count:
                count_copy += f'{domain_count} domains and {ip_count} IPs.'
            elif domain_count:
                count_copy += f'{domain_count} domains.'
            else:
                count_copy += f'{ip_count} IPs.'

            return {
                'severity': SEVERITY_MAPPINGS[parsed_rule['classification']],
                'name': parsed_rule['name'],
                'rawJSON': json.dumps({
                    'triggered_rule': parsed_rule['name'],
                    'rules': self._use_severity_titles([parsed_rule]),
                    'affected_hosts': examples,
                    '_incident_type': 'by_issue'
                }),
                'details': parsed_rule['details'] + count_copy,
                'occurred': timestamp_to_datestring(self.incident_created_time_ms)
            }

        @staticmethod
        def _build_examples(examples: List[Dict]) -> List[Dict]:
            """
            Parses out useful info from list of examples

            :param examples: list of entity
            :return: list of parsed fields
            """
            return [{'id': e['example'], 'metadata': e.get('target') or e.get('additional')} for e in examples]


    class ByHostIncident(ByHostIncidentBuilder):
        def build_incident(self, parsed_rule: Dict) -> Dict:
            raise NotImplementedError('Cannot use this method for this type of issue. Use build_grouped_incident instead')

        def build_grouped_incident(self, parsed_rules: List[Dict]) -> Dict:
            """
            ByHost incidents group all rules into a single incident

            :param parsed_rules: list of parsed rules
            :return: single incident
            """
            by_classification = self._group_by_classification(parsed_rules)
            title, severity = self._incident_title_and_severity(by_classification)
            details = self._incident_description(by_classification, len(parsed_rules))

            return {
                'name': title,
                'host': self.host,
                'details': details,
                'occurred': timestamp_to_datestring(self.incident_created_time_ms),
                'rawJSON': json.dumps({
                    '_incident_type': 'by_host',
                    'affected_hosts': [{'id': self.host, 'metadata': ''}],
                    'rules': self._use_severity_titles(list(sorted(parsed_rules,
                                                                   key=lambda r: SEVERITY_MAPPINGS[r['classification']],
                                                                   reverse=True)))
                }),
                'severity': severity
            }

        def build_incidents(self, parsed_rules: List[Dict]) -> List[Dict]:
            """
            Takes in parsed_rules and formats them as XSOAR Incident

            :param parsed_rules: parsed rules
            :return: list of Incident
            """
            return [self.build_grouped_incident(parsed_rules)]

        @staticmethod
        def _group_by_classification(rules: List[Dict]) -> Dict[str, List[Dict]]:
            """
            Groups rules by their classification

            :param rules: list of parsed rules
            :return: dict by classification
            """
            by_classification = defaultdict(list)
            for rule in rules:
                by_classification[rule['classification']].append(rule)
            return by_classification

        def _incident_title_and_severity(self, by_classification: Dict[str, List[Dict]]) -> Tuple[str, int]:
            """
            Generates a title for the incident

            :param by_classification: rules grouped by classification
            :return: title, severity
            """
            if by_classification['high']:
                severity = SEVERITY_MAPPINGS['high']
            elif by_classification['moderate']:
                severity = SEVERITY_MAPPINGS['moderate']
            else:
                severity = SEVERITY_MAPPINGS['informational']
            title = f'Attack Surface Risk Increase: {self.host} ' \
                    f'({self.previous_score} --> {self.risk_score})'
            return title, severity

        def _incident_description(self, by_classification: Dict[str, List[Dict]], added_rule_count: int) -> str:
            """
            Builds description for the incident

            :param by_classification: rules grouped by classification
            :param added_rule_count: how many rules were added?
            :return: description
            """
            summary = f'Summary for host "{self.host}":\n----------------------------\n'
            risk_score_diff = self.risk_score - self.previous_score
            change_symbol = '+' if risk_score_diff > 0 else '-'
            change_statement = f'{change_symbol}{abs(risk_score_diff)} from last Risk Score at {self.previous_snapshot}'
            summary += f'    {self.risk_score} Risk Score ' + (
                '(first score)' if not self.previous_score else f'({change_statement})') + '\n'
            summary += f'    {added_rule_count} New Risks ('
            rule_counts = []
            for criticality, rules in by_classification.items():
                if rules:
                    rule_counts.append(f'{len(rules)} {CRITICALITY_TITLES[criticality]}')
            summary += ', '.join(rule_counts)
            summary += ')'
            return summary


    class ByHostByIssueIncident(ByHostIncidentBuilder):
        def build_incident(self, parsed_rule: Dict) -> Dict:
            return {
                'severity': SEVERITY_MAPPINGS[parsed_rule['classification']],
                'name': f'{parsed_rule["name"]} [{self.host}]',
                'rawJSON': json.dumps({
                    'host': self.host,
                    'triggered_rule': parsed_rule['name'],
                    'rules': self._use_severity_titles([parsed_rule]),
                    'affected_hosts': [{'id': self.host, 'metadata': parsed_rule['metadata']}],
                    '_incident_type': 'by_host_by_issue'
                }),
                'details': parsed_rule['details'],
                'occurred': timestamp_to_datestring(self.incident_created_time_ms)
            }


    ''' COMMAND FUNCTIONS '''


    def test_module(client: Client) -> str:
        """
        Tests that the client can authenticate and pulls issues correctly

        :param client: Client
        :return: 'ok' if everything works otherwise raise an Exception
        """
        try:
            client.get_project_issues('recent')
        except DemistoException as e:
            if 'Forbidden' in str(e):
                return 'Authorization Error: make sure API Key is correctly set'
            else:
                raise e
        return 'ok'


    def _fetch_project_incidents(client: Client) -> Tuple[List[Dict], int]:
        """
        Fetches the most recent set of issues for a project to initialize incidents

        :param client: Client
        :return: list of incidents, total possible incidents
        """
        issues_resp = client.get_project_issues(snapshot='recent')
        recent_snapshot = issues_resp.get('meta', {}).get('snapshot')
        incident_builder = ByIssueIncident(client.min_severity, recent_snapshot)

        parsed_rules = incident_builder.parse_rules(issues_resp.get('data', []))
        if not parsed_rules:
            return [], 0

        return incident_builder.build_incidents(parsed_rules), len(parsed_rules)


    def _fetch_recent_incidents_by_host(client: Client, start_timestamp: int,
                                        expand_incidents: bool) -> Tuple[List[Dict], int]:
        """
        Fetch recent incidents after a certain timestamp grouped by hosts that changed

        :param client: Client
        :param start_timestamp: the timestamp to find new issues afterwards (usually the last_fetch)
        :param expand_incidents: whether to use ByHostIncident or ByHostByIssueIncident
        :return: list of incidents, total possible incidents
        """
        issues_resp = client.get_recent_issues_by_host(last_run=start_timestamp)

        # Initialize an empty list of incidents to return
        # Each incident is a dict with a string as a key
        incidents: List[Dict[str, Any]] = []

        for diff in issues_resp.get('data', []):
            diff_snapshot = diff.get('snapshot')
            build_cls = ByHostByIssueIncident if expand_incidents else ByHostIncident
            incident_builder = build_cls(
                diff['id'], diff['risk_score'], diff['previous_risk_score'], diff['previous_snapshot'],
                client.min_severity, diff_snapshot, last_checked=start_timestamp)
            parsed_rules = incident_builder.parse_rules(diff.get('added_rules', []))
            if not parsed_rules:
                continue
            incidents.extend(incident_builder.build_incidents(parsed_rules))

        return incidents, issues_resp.get('meta', {}).get('counts', {}).get('hosts', {}).get('total', 0)


    def _fetch_recent_incidents(client: Client, start_timestamp: int) -> Tuple[List[Dict], int]:
        """
        Fetch recent incidents after a certain timestamp

        :param client: Client
        :param start_timestamp: the timestamp to find new issues afterwards (usually the last_fetch)
        :return: list of incidents, total number of incidents
        """
        issues_resp = client.get_recent_issues(last_run=start_timestamp)

        # Initialize an empty list of incidents to return
        # Each incident is a dict with a string as a key
        incidents: List[Dict[str, Any]] = []

        for diff in issues_resp.get('data', []):
            diff_snapshot = diff.get('snapshot')
            incident_builder = ByIssueIncident(client.min_severity, diff_snapshot, last_checked=start_timestamp)
            parsed_rules = incident_builder.parse_rules(diff.get('added_rules', []))
            if not parsed_rules:
                continue
            incidents.extend(incident_builder.build_incidents(parsed_rules))

        return incidents, len(incidents)


    def fetch_incidents(client: Client, last_run: Dict[str, int], is_by_host: bool,
                        expand_issues: bool) -> Tuple[Dict[str, int], List[dict]]:
        """
        This function retrieves new alerts every interval (default is 24 hours).

        :param client: Client
        :param last_run: dict with one key (last_fetch) that was when the integration last pulled incidents
        :param is_by_host: are incidents being grouped by host?
        :param expand_issues: whether to expand host groupings by each issue as well
        :return: the new last_run and a list of incidents
        """

        # Get the last fetch time, if exists
        # last_run is a dict with a single key, called last_fetch
        last_fetch = last_run.get('last_fetch', None)

        if not is_by_host:
            if last_fetch is None:
                incidents, total = _fetch_project_incidents(client)
            else:
                incidents, total = _fetch_recent_incidents(client, last_fetch)
        else:
            incidents, total = _fetch_recent_incidents_by_host(client, last_fetch or 0, expand_issues)

        incident_limit = client.host_incident_limit
        # NOTE :: Some APIs limit the number of results return, and we're also expanding issues on client side
        #         so need to check both total possible results and total processed results
        max_count = max(len(incidents), total)
        if max_count > incident_limit:
            # NOTE :: Make sure the highest severity incidents aren't trimmed
            incidents = list(sorted(incidents, key=lambda i: i['severity'], reverse=True))
            if len(incidents) >= incident_limit:
                # NOTE :: Need to add an incident warning of the limit being hit so trimming incidents to limit (minus 1)
                trim = max(incident_limit - 1, 0)
                incidents = incidents[:trim]
            incidents.append({
                'name': f'❗Attack Surface Intelligence: {max_count}+ Changes',
                'details': f'This Incident was created because Recorded Future Attack Surface Intelligence found '
                           f'additional incidents beyond the configured XSOAR limit of {incident_limit} or beyond the'
                           f' maximum allowed by the Risk Rules API.\n'
                           f'Please review additional changes within the ASI Portal.',
                'occurred': timestamp_to_datestring(int(time.time()) * 1000),
                'severity': IncidentSeverity.LOW
            })

        # Save the next_run as a dict with the last_fetch key to be stored
        next_run = {'last_fetch': int(time.time())}
        return next_run, incidents


    ''' MAIN FUNCTION '''


    def main() -> None:
        params = demisto.params()
        api_key = params.get("credentials", {}).get("password") or params.get("apikey")
        if not api_key:
            return_error('Please provide a valid API token')
        project_id = params.get("project_id")
        is_by_host = params.get('issue_grouping') == 'By Host'
        expand_issues = params.get('expand_issues', False)
        incident_limit = int(params.get('max_fetch', DEFAULT_HOST_LIMIT))
        min_severity = params.get('min_severity', DEFAULT_MIN_SEVERITY)

        # get the service API url
        base_url = 'https://api.securitytrails.com/v1/asi'
        verify_ssl = not params.get('insecure', False)
        proxy = params.get('proxy', False)
        command = demisto.command()
        demisto.debug(f'Command being called is {command}')
        try:
            headers = {
                'APIKEY': api_key
            }
            client = Client(
                base_url=base_url,
                verify=verify_ssl,
                proxy=proxy,
                project_id=project_id,
                min_severity=min_severity,
                host_incident_limit=incident_limit,
               # verify=True,
                headers=headers)

            command_args = demisto.args()
            if command == 'test-module':
                return_results(test_module(client))
            elif command == 'asi-project-issues-fetch':
                next_run, incidents = fetch_incidents(
                    client=client,
                    last_run={'last_fetch': int(command_args.get('issues_start', 0))},
                    is_by_host=command_args.get('group_by_host', 'false') == 'true',
                    expand_issues=command_args.get('expand_issues', 'false') == 'true'
                )
                demisto.incidents(incidents)
            elif command == 'fetch-incidents':
                next_run, incidents = fetch_incidents(
                    client=client,
                    last_run=demisto.getLastRun(),
                    is_by_host=is_by_host,
                    expand_issues=expand_issues
                )
                demisto.setLastRun(next_run)
                demisto.incidents(incidents)

        # Log exceptions and return errors
        except Exception as e:
            demisto.error(traceback.format_exc())  # print the traceback
            return_error(f'Failed to execute {command} command.\nError:\n{str(e)}')


    ''' ENTRY POINT '''

    if __name__ in ('__main__', '__builtin__', 'builtins'):
        main()

    register_module_line('RecordedFutureASI', 'end', __line__())
  subtype: python3
  type: python
sourcemoduleid: RecordedFutureASI
